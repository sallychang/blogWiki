# 实验报告

## 实验目的

最终目标是为了在不同的环境下，能够仅根据访问量/CPU占用率/内存占用率/IO等数据就完成对不同实例数时服务性能的预测（响应时间/CPU占用率等指标）

因此本实验的目的在于，探索不同流量、不同实例数下时容器的状态会发生什么样的改变

## 理论支持与思考

目前来说有一篇文章对这方面的研究比较深入。就是Web Application Resource Requirements Estimation based on the Workload Latent Features。这篇文章着重研究的是不同的URI（请求）的混合给容器带来的不同压力。作者使用了四个不同比例混合的RUBiS流量，在相同的访问率下会得到完全不同的结果。但是对这个方向也是比较有帮助的。另外比较好的文章是Less Provisioning: A Hybrid Resource Scaling Engine for Long-running Services with Tail Latency Guarantees。这篇文章完全是从访问量和CPU占用率之间的关系来进行资源估计的。尽管不想承认，但是这种完全从数值出发而不管底层逻辑的方式可能是最终最好的方法。

当然，我还是希望我能够从底层出发能够解释现象并且完成对容器状态的预测。

从这篇文章的实验中我观察到了一个现象，即在不同的阶段下容器似乎有着不同的状态。这个状态的意思是指，在不同的访问量下容器的其他指标随着访问量变动的幅度是有区别的。

在之前（五月份）的时候，我们曾经尝试对容器进行建模，去预测在具体有几个实例的时候容器的性能是什么样的，而不是说用强化学习+穷举法的思想。但是遇到的很明显的两个问题：

1. 同一个流量在不同的时候表现似乎完全不同，这可能与其前一时刻的流量访问量相关。即容器的状态似乎呈现出一种马尔科夫的性质。
2. 在同一个容器内的流量尚有预测的可能（准确度还能看），但是只要涉及到多个容器，则预测难度就会变得非常大（准确度完全不能看）。这方面可能要从底层进行建模，来考虑多层神经网络或者考虑变量之间的相关性。甚至要考虑到样本的关系，因为容器数量较大的时候往往样本数量比较小。

还有一点，是从底层出发的想法，即容器本质上是用cgroups和namespace隔离出来的部分，实质上是多线程程序。也就是说，容器的隔离程度是比虚拟机要低的，从CPU的角度来说，如果一个容器更多使用CPU的话，它将不可避免地受到所在机器的其他容器的影响（比如单个机器CPU占用率较高时）。在长期预测中如何去权衡、估计这种影响将是很关键的。

## 实验环境

* 实验环境：kubernetes/docker+istio+prometheus监控。目前部署在华为云上的就是这一套系统，因此使用代价是最小的。
* 实验对象：bookinfo应用
* 测试流量：线性增长流量/文本随机流量（从文本读入的固定长度流量）/完全随机流量，以上三个组重复多次
* 测试方法：atOnceUser。原因是这样子能够在达到上限前给予足够多的压力，不然压力太小效果不明显。

改进：
* 对于gatling而言，可以尝试使用constantUser或者类似session-based那种用户类型的访问测试。
* 可以尝试不使用gatling进行测试，目前正在主页整理其他论文所使用的流量测试工具。
* 可以不使用istio的bookinfo进行测试，如上，正在整理。其中比较常用的是RUBiS应用，不知道有没有容器版本。
* 可以尝试修改配置信息，比如CPU配额、内存配额等，以及实例数


