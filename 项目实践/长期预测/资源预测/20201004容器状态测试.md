# 实验报告

## 实验目的

最终目标是为了在不同的环境下，能够仅根据访问量/CPU占用率/内存占用率/IO等数据就完成对不同实例数时服务性能的预测（响应时间/CPU占用率等指标）

因此本实验的目的在于，探索不同流量、不同实例数下时容器的状态会发生什么样的改变

## 理论支持与思考

目前来说有一篇文章对这方面的研究比较深入。就是Web Application Resource Requirements Estimation based on the Workload Latent Features。这篇文章着重研究的是不同的URI（请求）的混合给容器带来的不同压力。作者使用了四个不同比例混合的RUBiS流量，在相同的访问率下会得到完全不同的结果。但是对这个方向也是比较有帮助的。另外比较好的文章是Less Provisioning: A Hybrid Resource Scaling Engine for Long-running Services with Tail Latency Guarantees。这篇文章完全是从访问量和CPU占用率之间的关系来进行资源估计的。尽管不想承认，但是这种完全从数值出发而不管底层逻辑的方式可能是最终最好的方法。

当然，我还是希望我能够从底层出发能够解释现象并且完成对容器状态的预测。

从这篇文章的实验中我观察到了一个现象，即在不同的阶段下容器似乎有着不同的状态。这个状态的意思是指，在不同的访问量下容器的其他指标随着访问量变动的幅度是有区别的。

在之前（五月份）的时候，我们曾经尝试对容器进行建模，去预测在具体有几个实例的时候容器的性能是什么样的，而不是说用强化学习+穷举法的思想。但是遇到的很明显的两个问题：

1. 同一个流量在不同的时候表现似乎完全不同，这可能与其前一时刻的流量访问量相关。即容器的状态似乎呈现出一种马尔科夫的性质。
2. 在同一个容器内的流量尚有预测的可能（准确度还能看），但是只要涉及到多个容器，则预测难度就会变得非常大（准确度完全不能看）。这方面可能要从底层进行建模，来考虑多层神经网络或者考虑变量之间的相关性。甚至要考虑到样本的关系，因为容器数量较大的时候往往样本数量比较小。

还有一点，是从底层出发的想法，即容器本质上是用cgroups和namespace隔离出来的部分，实质上是多线程程序。也就是说，容器的隔离程度是比虚拟机要低的，从CPU的角度来说，如果一个容器更多使用CPU的话，它将不可避免地受到所在机器的其他容器的影响（比如单个机器CPU占用率较高时）。在长期预测中如何去权衡、估计这种影响将是很关键的。

## 实验环境

* 实验环境：kubernetes/docker+istio+prometheus监控。目前部署在华为云上的就是这一套系统，因此使用代价是最小的。
* 实验对象：bookinfo应用
* 测试流量：线性增长流量/文本随机流量（从文本读入的固定长度流量）/完全随机流量，以上三个组重复多次
* 测试方法：atOnceUser。原因是这样子能够在达到上限前给予足够多的压力，不然压力太小效果不明显。

改进：
* 对于gatling而言，可以尝试使用constantUser或者类似session-based那种用户类型的访问测试。
* 可以尝试不使用gatling进行测试，目前正在主页整理其他论文所使用的流量测试工具。
* 可以不使用istio的bookinfo进行测试，如上，正在整理。其中比较常用的是RUBiS应用，不知道有没有容器版本。
* 可以尝试修改配置信息，比如CPU配额、内存配额等，以及实例数

## 实验内容

### 实验1

实验具体内容：限定实例数为1，使用不同的流量进行测试。流量变动间隔为10s，取样均为4s取样。流量测试的数据点为60个点，总时间为10分钟。

三个流量内容，每个内容重复3遍。

对结果进行数据分析，主要是对流量、CPU、响应时间的关系进行统计。

#### 测试脚本

* 线性增长脚本。其内容为在10分钟内每10s进行一次递进，总共进行60次递增。
* 文本脚本。对于线性增长的60次递增的值进行重排，并且读取文件执行。
* 随机脚本。对于线性增长的60次递增的值进行现场重排，并且执行。

150以内成功率为100%，150以上成功率不为100%。因此对150进行分界。
* 情况1：最大访问率上界不超过150，最小为30.
* 情况2：最大会超过150.

#### 期望结果与原理

目的是为了探索本时刻状态与上一时刻状态之间的关系。

计划是多次取平均后重新排序绘制流量->响应时间图与流量->CPU占用率图。

目前是可以发现服务成功率下降后曲线会发生很明显的变化。还没有确定节点CPU占用率过高是否会对容器产生影响。


#### 代码-线性增长

* 线性增长-第一次实验：2020/10/05 12:31:50 ~ 12:41:50
* 线性增长-第二次实验：2020/10/05 12:46:00 ~ 12:56:00
* 线性增长-第三次实验：2020/10/05 18:14:35 ~ 18:24:35

* 20:46:00~20:56:00

```
package wtytest
import java.util.Calendar;
import io.gatling.core.Predef._
import io.gatling.jdbc.Predef._
import io.gatling.http.Predef._
import scala.io.Source
import scala.concurrent.duration._
import scala.collection.mutable.ArraySeq
import io.gatling.core.structure.PopulationBuilder

class SimpleTestOrigin extends Simulation {
    val httpProtocol = http
    .baseUrl("http://139.9.57.167:19080")
    .acceptHeader("text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8")
    .doNotTrackHeader("1")
    .acceptLanguageHeader("en-US,en;q=0.5")
    .acceptEncodingHeader("gzip, deflate")
    .userAgentHeader("Mozilla/5.0 (Macintosh; Intel Mac OS X 10.8; rv:16.0) Gecko/20100101 Firefox/16.0");
    def scnList() = {
        var step = 1;
        var scnList = new ArraySeq[PopulationBuilder](600/step);
        for (i <- 0 until 600 by step) {
            var rn = 0;
            rn = (i/10).toDouble.toInt*2+30;
            var scen = scenario("Normal Access" + i)
                .exec(http("send request").get(""))
                .inject(
                    nothingFor(i seconds),
                    atOnceUsers(rn)
                );
            scnList(i/step) = scen;
        }
        scnList;
    }

    setUp(scnList: _*).protocols(httpProtocol)
}
```

#### 代码-文本增长

* 第一次实验：2020/10/05 9:12:45~9:22:45
* 第二次实验：2020/10/05 11:56:25~12:06:25
* 第三次实验：2020/10/05 12:08:50~12:18:50

脚本生成：

```python
import random
import numpy as np

data = np.arange(30,150,2)
random.shuffle(data)
f = open('wtytest','w')
for d in data:
    f.write(str(d)+'\n')

f.close()
```

生成的文件：wtytest

```
44
38
136
76
102
104
108
62
144
46
60
70
138
112
64
126
134
72
116
120
36
80
34
32
94
48
128
124
90
66
42
88
52
78
84
100
122
148
98
54
132
68
30
92
142
58
106
146
96
140
74
130
56
82
50
40
118
86
110
114
```

```scala
package wtytest
import java.util.Calendar;
import io.gatling.core.Predef._
import io.gatling.jdbc.Predef._
import io.gatling.http.Predef._
import scala.io.Source
import scala.concurrent.duration._
import scala.collection.mutable.ArraySeq
import io.gatling.core.structure.PopulationBuilder

class SimpleTestFile extends Simulation {
    val httpProtocol = http
    .baseUrl("http://139.9.57.167:19001")
    .acceptHeader("text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8")
    .doNotTrackHeader("1")
    .acceptLanguageHeader("en-US,en;q=0.5")
    .acceptEncodingHeader("gzip, deflate")
    .userAgentHeader("Mozilla/5.0 (Macintosh; Intel Mac OS X 10.8; rv:16.0) Gecko/20100101 Firefox/16.0");

    val source = Source.fromFile("wtytest","UTF-8")
    val lines = source.getLines().toArray
    source.close()

    def scnList() = {
        var step = 1;
        var scnList = new ArraySeq[PopulationBuilder](600/step);
        for (i <- 0 until 600 by step) {
            var rn = 0;
            rn = lines(i/10).toDouble.toInt;
            var scen = scenario("Normal Access" + i)
                .exec(http("send request").get(""))
                .inject(
                    nothingFor(i seconds),
                    atOnceUsers(rn)
                );
            scnList(i/step) = scen;
        }
        scnList;
    }

    setUp(scnList: _*).protocols(httpProtocol)
}
```

#### 代码-随机增长

即输入文本增长的序列，但是每次都要进行重排。

原本打算使用scala数组+重排的，但是发现好像不会scala，很尴尬。目前的想法是将现有的文本再次随机打乱，然后塞进去，用上一章的代码……

##### 第一个文件

* 第一次实验：2020-10-05/19:37:20 ~ 19:47:20

```
108
128
148
74
70
116
92
106
76
50
114
68
118
98
62
102
56
64
134
130
140
54
40
126
90
78
86
144
96
60
36
104
120
32
132
44
58
66
146
138
52
112
48
30
72
46
100
38
42
122
34
110
82
142
124
136
94
80
84
88
```

##### 第二个文件

* 第二次实验：2020-10-05/20:31:15 ~ 20:41:15

```
124
80
56
146
100
74
114
138
126
106
86
122
36
44
116
140
134
94
46
60
58
98
34
30
76
112
32
136
78
40
128
54
88
84
72
62
144
92
104
130
70
64
110
108
66
68
90
118
132
120
142
82
42
102
52
96
148
50
38
48
```

##### 第三个文件

* 第三次实验：2020-10-06/20:34:20

```
34
126
132
140
114
104
54
50
138
84
122
30
76
52
88
90
32
60
136
80
142
58
120
46
112
134
130
100
74
68
48
92
40
102
98
128
78
38
42
62
56
36
82
72
66
106
86
44
148
146
118
94
64
144
70
116
108
124
96
110
```

#### 信息处理脚本

首先遍历所有文件夹。对于每一个大文件夹，使用同一个记录系统统计流量与响应时间/CPU的关系并取平均。