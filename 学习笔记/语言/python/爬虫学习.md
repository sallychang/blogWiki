# 爬虫快速入门

## requests

### 参考资料

* [中文站](https://requests.readthedocs.io/zh_CN/latest/)


### 1 快速入门

在requests中，它会使用urllib3来自动完成Keep-alive和自动保持HTTP连接等功能。

* 使用`requests.get(url)`即可发送一个get请求
* 使用`requests.post(url,data={key,value})`可以发送一个POST请求。

同理，put,delete,head与options都可以这样发送。

#### 传递参数

有时会需要向URL的查询字符串中传递某种数据。如果是手工构建的话，需要向URL中插入键值对，并进行转码，例如`httpbin.org/get?key=val`

在requests中，可以使用params参数进行，例如`payload = {'key1': 'value1', 'key2': 'value2'}`,`r = requests.get("http://httpbin.org/get", params=payload)`。

也可以将多个值用列表形式传入：
```python
>>> payload = {'key1': 'value1', 'key2': ['value2', 'value3']}

>>> r = requests.get('http://httpbin.org/get', params=payload)
>>> print(r.url)
http://httpbin.org/get?key1=value1&key2=value2&key2=value3
```

##### 定制请求头

如果需要添加HTTP头部，则要传递一个dict给对应方法的headers参数，比如需要指定`content-type`时：
```python
>>> url = 'https://api.github.com/some/endpoint'
>>> headers = {'user-agent': 'my-app/0.0.1'}

>>> r = requests.get(url, headers=headers)
```

header的值必须是string、bytestring或者unicode。但是不建议传递unicode header

##### 传递复杂的POST请求

比如表单之类的，需要传递一个字典给data参数：
```python
>>> payload = {'key1': 'value1', 'key2': 'value2'}

>>> r = requests.post("http://httpbin.org/post", data=payload)
>>> print(r.text)
{
  ...
  "form": {
    "key2": "value2",
    "key1": "value1"
  },
  ...
}
```

如果是同一个key下的多个元素，可以使用元组列表：
```python
>>> payload = (('key1', 'value1'), ('key1', 'value2'))
>>> r = requests.post('http://httpbin.org/post', data=payload)
>>> print(r.text)
{
  ...
  "form": {
    "key1": [
      "value1",
      "value2"
    ]
  },
  ...
}
```

如果发送数据并非编码为表单形式，可以传递一个string。比如如果对方接受JSON格式数据，可以这样`payload = {'some': 'data'}`,`r = requests.post(url, data=json.dumps(payload))`。

当然，也可以直接用json参数传递`r = requests.post(url, json=payload)`，新版本会自动完成编码。

#### 响应内容

可以在调用上述方法后通过requests.models.Response对象来获得服务器响应的内容。

* r.text，可以获得unicode编码的内容。（比如对于网页而言，会返回网页的源码）
* r.encoding,通过这个属性，可以显示并改变r.text的编码。（每次访问r.text时，Requests都会使用新值进行解码）可以使用自己的编码，并用codecs模块进行注册
* r.content，使用字节的方式访问请求响应体（返回的字符串会带上b）。Requests会自动为你解码gzip和defalte传输编码的数据，例如使用`i = Image.open(BytesIO(r.content))`可以直接得到图片文件。
* r.json()：这是一个方法，可以调用Requests内置的JSON解码器来处理JSON数据。正常情况下会返回一个UTF-8编码的字典，如果没有JSON数据会报错（JSONDecodeError）；根据官网说法，解码错误还会报ValueError。解码正确也并不一定响应成功，因为有些服务器在失败的响应中同样是含有JSON对象的，需要进行检查
* r.raw：该属性包含了最原始的套接字响应。获取该属性**必须**要在初始请求中设置`stream=True`。可以使用`r.raw.read(n)`来读取前n个字节。但是一般情况是将文本流保存到文件读取：
```python
with open(filename, 'wb') as fd:
    for chunk in r.iter_content(chunk_size):
        fd.write(chunk)
```

此外，还有一些方便的属性
* r.headers可以拿到响应的请求头，形式时字典形式，仅为HTTP头部工作，字段不区分大小写。
* r.status_code，返回整数形式的状态码。（Requests有内置的状态码查询对象，如`requests.codes.ok`，有在面对错误请求时抛出异常的方法`r.raise_for_status()`，这个方法只在非200时报错）
* r.cookies，是一个字典，可以通过`cookie_name`来得到cookie的值。发送时可以使用cookies参数来在对应方法中发送

#### Cookie
requests中的RequestsCookieJar是一个功能强大的对象，接口比字典更完整，适合跨域名跨路径使用。
``` python
>>> jar = requests.cookies.RequestsCookieJar()
>>> jar.set('tasty_cookie', 'yum', domain='httpbin.org', path='/cookies')
>>> jar.set('gross_cookie', 'blech', domain='httpbin.org', path='/elsewhere')
>>> url = 'http://httpbin.org/cookies'
>>> r = requests.get(url, cookies=jar)
>>> r.text
'{"cookies": {"tasty_cookie": "yum"}}'
```

#### 重定向

默认情况下，Requests会处理除了HEAD以外的重定向。可以使用`r.history`来追踪重定向，这会返回一个列表，按照从最老到最新的请求进行排序。

可以在方法中使用`allow_redirects`参数来控制重定向是否允许发生。

#### 超时

可以告诉requests在`timeout`参数设定的秒数之后停止响应。基本上所有生产代码都应该使用这一擦拭农户，否则可能程序将永久失去响应。

到达时间后，方法会抛出`requests.exceptions.Timeout`错误。

注意：timeout仅对连接过程有效而与响应体的下载无关。即如果服务器在timeout秒内没有应答（没有从基础套接字上接收任何字节的数据），将会引发一个异常。

#### 错误与异常

* 遇到网络问题（DNS查询失败，拒绝连接）会抛出：`ConnectionError`异常
* 如果HTTP请求返回了不成功的状态码，`Response.raise_for_status()`会抛出`HTTPError`异常
* 如果请求超时，会抛出一个`Timeout`异常
* 如果请求超出了设定的最大重定向次数，会抛出一个`TooManyRedirects`异常

所有Requests显式抛出的异常都继承自`requests.exceptions.RequestException`中。

### 高级用法

#### 会话对象

会话对象可以在同一个Session实例发出的所有请求之间保持cookie。会复用底层的TCP连接，因此如果向同一个主机发送多个请求的话效率会有所提升。

Session的使用可以跨请求保持Cookie，也可以为请求方式提供缺省数据（通过为会话对象的属性提供数据来实现，如下）：

```python
s = requests.Session()
s.auth = ('user', 'pass')
s.headers.update({'x-test': 'true'})

# both 'x-test' and 'x-test2' are sent
s.get('http://httpbin.org/headers', headers={'x-test2': 'true'})
```

传递给请求方法的字典会与已经设置的会话层数据合并，方法的参数会覆盖会话的参数。

注意：方法级别的参数不会被保持

```python
s = requests.Session()

r = s.get('http://httpbin.org/cookies', cookies={'from-my': 'browser'})
print(r.text)
# '{"cookies": {"from-my": "browser"}}'

r = s.get('http://httpbin.org/cookies')
print(r.text)
# '{"cookies": {}}'
```

#### 请求与响应对象

在进行类似requests.get()的调用时，进行了两项操作，一项时构建了一个Request对象，另一项工作是一旦requests得到了一个从服务器返回的响应，会产生对应的Response对象，包含之前那个request对象。

因此，访问请求头也可以这么访问`r.requests.headers`

#### 准备的请求Prepared Request

#### SSL证书认证

Requests可以为HTTPS请求验证SSL证书，默认是开启的。如果整数验证失败会抛出`SSLError`。（或者在方法中指定`verify=True`）

可以使用`verify`参数来传入CA_BUNDLE文件的路径，或者包含可信任CA证书文件的文件夹路径。

#### 客户端证书

可以指定一个本地证书作为客户端证书。`requests.get('https://kennethreitz.org', cert=('/path/client.cert', '/path/client.key'))`

#### 响应体内容工作流

默认情况下，一旦进行网络请求，响应体就会被下载。可以通过`stream`参数覆盖这个行为，推迟下载响应体直到访问`Response.content`属性：`r = requests.get(tarball_url, stream=True)`

此时，requests只会下载响应头。

可以使用`Response.iter_content`和`Response.iter_lines`来控制工作流或者用`Response.raw`直接读取未解码的响应体。

#### 流式上传

Requests支持流式上传，此时上传大文件时就不需要先将它们全部读入内存。

```python
with open('massive-body') as f:
    requests.post('http://some.url/streamed', data=f)
```

PS：官方强烈建议使用二进制打开文件，不然可能会因为Content-Length设置问题导致错误。

#### 事件挂钩

Requests有一个钩子系统，可以用来操控部分请求过程，或者信号事件处理。

可以通过传递一个`{hook_name : callback_function}`字典给`hooks`请求参数为每个请求分配一个钩子函数。

例如`requests.get('http://httpbin.org', hooks=dict(response=print_url))`

callback如下：（会接受一个数据块作为它的第一个参数）
```python
def print_url(r, *args, **kwargs):
    print(r.url)
```

#### 流式请求

使用`Response.iter_lines()`可以很方便地应对流式API，即设置`stream=True`后使用`iter_lines`进行相应的迭代

```python
import json
import requests

r = requests.get('http://httpbin.org/stream/20', stream=True)

for line in r.iter_lines():

    # filter out keep-alive new lines
    if line:
        decoded_line = line.decode('utf-8')
        print(json.loads(decoded_line))
```

#### 代理

如果需要使用代理，则要为任意的请求方法提供`proxies`参数来配置单个请求。

```python
import requests

proxies = {
  "http": "http://10.10.1.10:3128",
  "https": "http://10.10.1.10:1080",
}

requests.get("http://example.org", proxies=proxies)
```

也可以配置系统环境变量`HTTP_PROXY`和`HTTPS_PROXY`来完成代理的配置。（此时就不用显式指明）

HTTP Basic Auth:
```python
proxies = {
    "http": "http://user:pass@10.10.1.10:3128/",
}
```

若要为某个特定的连接方式或主机设置代理，则使用`scheme://hostname`作为key。
`proxies = {'http://10.20.1.128': 'http://10.10.1.10:5323'}`，注意代理URL必须包含连接方式。

除了基本的HTTP代理，Requests还支持SOCKS协议代理。需要安装第三方库`pip install requests[socks]`

代理与HTTP类似：
```python
proxies = {
    'http': 'socks5://user:pass@host:port',
    'https': 'socks5://user:pass@host:port'
}
```


## beautifulSoup

