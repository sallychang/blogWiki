# 微服务弹性调度论文阅读

标签：微服务 弹性调度 论文

## 一些定义

云计算的可扩展性：根据实时的服务请求或者工作负载，尽力保证分配合理粒度的系统资源能够适合实时的服务系统性能，而无需用户对峰值负载进行资源重置。

扩展资源的量纲：通常在一个云计算系统中可供弹性调度的资源种类至少有一种或者很多种。每一种资源类型都可以单独的作为一个量纲，如果一个资源类型包含其他资源类型，就像虚拟机类型的资源，就包含CPU内核和RAM这两种资源类型。一般在云计算系统中，可以被配置的资源是离散的单元，有三种：CPU内核、虚拟机、物理节点。划分的粒度逐渐增大，在弹性扩展中对云服务的影响也是不同的。

## Kubernetes的运行模式

Kubernetes Scheduler是运行在Master节点上的调度器，它通过监听Apiserver来将Pod调度到合适的Node上。调度过程如下：

1. 第一步：Predicate，过滤掉不满足资源条件的节点。
2. 第二步：Priority，计算各个节点的CPU和内存使用率权重（最多支持对CPU、内存和GPU）。使用率越低权重越高，计算镜像权重，镜像越大，权重越高，倾向于调度到已经有需要用到的镜像的节点，由此来对各个节点打分，以确定他们的优先级顺序，选择打分最高的节点作为Pod运行的Node。

局限性：

1. 只考虑CPU和内存的动态资源配置机制，是不够现实的，还有很多影响因素，比如网络和I/O还有存储。
2. Kubernetes的权重打分机制倾向于将workload平均分布在各个节点，一方面在资源高效利用方面存在不足，除了应用高峰期，其他时间整个集群都处于低负载状态，同时增加了数据中心的能耗。
3. 另外一方面，资源均分一定程度造成资源碎片化，降低了集群资源利用率，也可能造成新进的大资源无法部署永远处于Pending状态。

## 《基于Kubernetes的资源动态调度的研究与实现》-杨鹏飞

### 资源调度介绍

按照不同的资源调度时机分类，资源调度机制可以分为静态调度、动态调度和部分动态调度三种。

* 静态资源调度：要求应用对资源的使用量基本保持不变，在资源申请的最初阶段就已完成资源的静态分配，并且在应用运行期间不再改变。
* 动态调度：在应用运行期间周期性的统计资源使用情况，根据实际消耗的资源量，动态的调整应用的资源申请配额。目的是按需分配，充分利用资源，得到一个近似的资源分配最优解。
* 部分动态调度：一部分系统资源的工作在系统的最初的阶段完成，另一部分资源配置工作在应用运行时根据资源负载情况动态的调整资源的分配。目标是以消耗特定的计算资源为代价，来换取一个近似最优的资源配置。

Kubernetes系统中，资源调度的工作主要由Scheduler组件负责，使用静态调度。缺点：只在应用初次部署时进行资源配置，无法按需分配。其次，缺乏预测，不能在资源指标违例之前发出警报。容易造成Node节点上对单一资源的瓶颈。

### 第3章 资源使用量预测模型

时间序列预测算法，比如ARIMA（autoregressive Intergrated Moving Average Model）和神经网络

#### 单一预测模型

##### ARIMA

差分自回归移动平均模型，运用于随机行时间序列预测，在时间序列分析方式中，被认为是最高级、最有效的分析方法。

思想：在时间序列中，单个的值虽然具有随机性和不确定性，但整个时间序列却有规律可循，可以用ARIMA模型进行类似的描述。

本质上是三种模型的结合：用于处理线性问题的AR(p)模型（自回归模型）、加入平均滑动的MA(q)模型（移动平均模型）和针对平稳时间序列的ARMA(p,q)模型（自回归移动平均模型）。

* AR模型：一个p阶的自回归模型简称为AR(p)，如果在一个时间序列中，对于某一个时刻t的值yt与过去p个时刻的值有关，就可以用AR模型来表示。yt可表示为历史值的线型组合加上t时刻的白噪声干扰项。其中白噪声序列需要确保为零均值序列。
* MA模型：一个q阶的移动平均模型简称为MA(q)，如果在一个时间序列中，对于任意时刻t的值yt都可以由过去q个时刻的残差序列dt的加权平均值和来表示，则该序列可以用AM(q)来表示。
* ARMA模型：当时间序列对于任意时刻t的值yt不仅和历史值有关，还跟外部的干扰有关，并且两者存在一定的依存关系，在进行数据拟合的时候，为了保证模型有更大的灵活性，在模型中增加了移动平均部分，并结合自回归模型功能组合成自回归移动平均模型。即一个p阶自回归模型与q阶滑动平均模型组合成。

上述模型都是描述平稳序列的，然而在现实中遇到的时间序列多数为非平稳序列。为了将其平稳化，通常应用一次差分或多次差分把原序列转换为平稳序列。一个序列若能通过差分转换成平稳序列，则被称为齐次非平稳序列。差分的次数称为齐次的阶数。

##### RBF神经网络模型

人工神经网络ANN，以网络拓扑知识为理论基础，模拟人脑的神经系统对复杂信息的处理机制的一种数学模型。

径向基函数神经网络RBF，利用了多维空间中传统的严格差值法的研究成果。在神经网络的背景下，隐藏单元提供一个“函数”集，该函数集在输入模式向量扩展至隐层空间时为其构建了一个任意的“基”；这个函数集中的函数被称为径向基函数。

基本的径向基函数是具有单隐层的三层前馈网络，是一种局部逼近网络，能以任意精度逼近任一连续函数。

常规学习算法，一般包括两个不同的阶段：

* 隐含层径向基函数的中心的确定阶段。常见方法有随机选取固定中心法，中心的自组织选择法等。
* 径向基函数的权值学习调整阶段。常见方法有中心的监督选择法、正则化严格插值法等。

#### ARIMA与RBF组合模型

ARIMA的局限：时间序列的预测值被假定为与过去的真实值和误差值之间是线性关系，但是现实中的时间序列不仅具有线性关系，还具有非线性关系。

#### 预测效果评估指标

1. 绝对平均误差MAE = 真实值-实际值的绝对值的平均数
2. 绝对平均百分比误差MAPE = 真实值-预测值/真实值的绝对值的平均数
3. 均误差RMSE= 真实值 - 绝对值的平方的平均数
4. 均方根误差RMSE = sqrt(RMSE )


### 第4章 资源动态调度的设计与实现

#### 调度过程

1. 在开始调度之前，清算已经被删除、停止或者异常崩溃的实例，收回这些实例借出去以及借进来的资源。
2. 排除运行时间不足的实例，因为这些实例的资源使用量数据不足，达不到模型的训练效果。
3. 遍历所有实例，将所有可借出资源R的实例的资源总量暂存起来，交由动态分配程序保管。
4. 遍历所有实例，因为可借的资源要优先满足所有上一轮作为贷方实例的需求量。如果可借资源刚好满足所有这些实例的需求量，那就执行调度决策这一步；如果还剩可借资源，就执行下一步；不然，就将空缺的资源需求将借方的资源按比例回收，然后执行调度策略。
5. 如果还剩下可借的资源，将剩下需要资源的实例按需求量从大到小排序，然后依次满足这些实例的需求量。
6. 将最终所有的调度决策全部应用于Pod以及Pod里运行的容器中，等待下一周期的调度。

#### 实现自动伸缩模块

弹性伸缩Auto Scaling：根据不同的业务需求与策略，自动调整应用的弹性计算资源，最终达到优化资源组合的服务能力。

在业界有两个方向：一个是垂直伸缩scale up，即单个实例可以使用的资源的增域；一个式水平伸缩scale out，即应用实例数目的增减。

目前版本的kubernetes仅提供对用户根据检测到的应用负载情况，手动更改实例数进行计算资源的水平伸缩能力处理。

针对CPU使用率和内存进行考量，选取最大的资源使用比率，然后进行调整。

#### 负载均衡模块

Kubernetes关于Pod的负载均衡功能实现在Scheduler组件中，通过特定的调度算法将待调度的Pod部署到指定的Node节点上。Scheduler调度过程如下：

* 从待调度的Pod缓存队列中取出一个Pod对象。
* 遍历Kubernetes中的Node节点列表，依次检验其是否满足待调度Pod的资源请求量。如果存在多个满足条件的Node节点，则根据相应的标准进行评分。不存在满足条件的Node节点，则产生此次调度失败的事件信息。一旦成功选择了一个可用的Node节点，那么使用该Pod的namespace、Pod名称、选择的Node节点这三个属性新建一个Binding对象。
* 将Pod调度到指定的Node节点上运行，这个动作也叫做绑定bind。bind是Scheduler向API Server返回生成的Binding对象，该Binding对象最后由API Server调用etcd接口来持久化存储。同时API Server会在etcd中更新boundPounds对象，它是保存该Node节点上所有运行着的Pod信息。

综上，可以将Kubernetes的Scheduler看成是一个黑盒，黑盒的输入就是等待调度的Pod与可用的Node节点列表；输出就是从可用的Node节点列表中根据一定的调度策略，选出一个最适合的Node节点。待调度Pod与Node节点的组合即为Binding对象。

早期版本的Scheduler调度算法只有简单的轮询Round Robin，即随机从可用的Node节点列表中选取一个Node节点，并将待调度的Pod调度到该Node节点上运行。

##### 实现算法

向Scheduler注册新的调度算法需要提供两个要素：算法名和算法实现函数。

调度算法可分为两大类：Predicateds和Priorities，其中Predicates决定能否将Pod调度到某个Node节点上运行，而Priorities则是在Predicates给的Node节点打分来决定优先级。具体到Kubernetes自带的算法，Predicates包括：PodFitsResources(资源够用)、PodFitsPorts（端口是否冲突）、NoDiskConflict（挂载的磁盘是否冲突）。Priorities则包括：LeastRequestedPriority、ServiceSpreadingPriority和EqualPriority。

前面的三种Priorities算法虽然有考虑Node节点上的内存和CPU的负载情，但确忽略了应用对资源的消耗是不均衡的。如果将对同一资源敏感的应用部署到同一Node节点上，容易形成性能瓶颈。

应用要对资源的敏感程度来均衡调度。

## 《基于Kubernetes的容器自动伸缩技术的研究》-杨茂

自动伸缩：目的是提高应用应对负载动态变化的能力。自动伸缩就是系统根据应用负载变化自动调整资源供应的能力，应用负载过高的时候，系统自动增加资源供应以保障应用的服务质量；应用负载降低时，系统及时回收空闲资源，降低应用运行成本并提高资源利用率。

Kubernetes自动化伸缩服务的实现：通过周期性检查应用的负载状态，并根据一定的伸缩策略动态调整应用的资源供应。

问题：

1. 在扩容阶段，即应用负载增加需要增加资源供应时存在响应延迟问题。主要表现为增加资源供应存在一定的滞后性，导致应用的请求相应时间会在一段时间内增加，造成服务质量的下降。
2. 在缩容阶段，即应用处于相对空闲需要减少资源供应时，没有考虑到缩容对集群资源平衡的影响，造成集群整体资源使用不平衡，有增加集群产生资源碎片的可能性。

其他研究：

1. 基于阈值的伸缩方法。从静态阈值到动态阈值，再到多重阈值。实现简单，适应性强，但是需要云用户对应用特点以及云平台基础架构有深入的了解，并具有一定的专业知识才能够选取到合适的指标和阈值以及定义触发后响应动作。
2. 增强学习理论，通过大量先验知识的学习让系统学会如何在多种环境中进行自适应反应。这种方法能够自动化地进行学习和纠正，不断总结先前经验，最后根据应用的特点自动化的执行伸缩。优点是可以避免云用户自己定义伸缩计划并对长时间运行的应用表现出一定的智能化。缺点在于需要大量的时间去总结经验，在应用运行前期表现出较大的不确定性，而且对突发情况适应性差。
3. 还有基于负载预测的伸缩方法，根据负载预测结果制定伸缩计划。负载预测本身采用线性回归算法和字符串匹配算法，根据系统资源使用情况自动在两种算法之间进行切换。当集群资源利用率低时使用复杂度高的KMP字符串匹配算法，当资源利用率高时使用简单的线性回归算法。考虑到了预测方法对资源的适应性，但是没有考虑到负载本身的复杂性，以及单一的线性回归算法或KMP算法都存在一定的局限性。

### 第2章 相关理论与技术综述

#### Docker核心技术

Docker隔离技术，通过linux内核提供的namespace技术对容器进行隔离，目前linux namespace可以实现对主机名、进程通信IPC、进程PID、网络、文件系统挂载点以及用户的隔离。

Docker资源控制技术。通过namespace为容器提供一个较为完整的隔离环境，同时利用内核中的cgroups机制完成对容器资源的控制和审计。cgroups为每种可以控制的资源定义一个子系统，并通过这些子系统完成以下功能：

1. 资源限制：限制任务资源使用总额，比如对CPU的使用核数或百分比进行限制，对使用内存进行限制等。
2. 控制任务优先级：通过分配CPU时间片数量和磁盘I/O带宽的方式控制任务运行时的优先级。
3. 资源统计：统计系统的资源使用量，比如CPU使用时长、内存使用量等。
4. 进程控制：对任务执行挂起、恢复等操作

### 第3章 Kubernetes自动伸缩服务及伸缩策略

Kubernetes通过自动伸缩控制器HPA(Horizontal Pod Autoscaler)，周期性检查Pod副本集中所有副本的负载状态，自动调整副本数量，在保证应用服务质量的同时提高集群的资源利用率。它可以根据期望自动计算期望副本数，然后通过副本控制器RC定期检查期望副本数与当前真实副本数的数量，从而进行调整。

kubernetes现有伸缩策略在扩容阶段存在滞后现象的主要原因是从副本集负载过高触发扩容到新创建Pod副本提供服务需要一定的时间。这段时间为Pod初始化时间，构成如下：

![pod-init-time](img/pod-init-tiem.png)

* 阶段一：触发扩容到自动伸缩器HPA计算期望副本数并发送给副本控制器的间隔，t1表示其所用的时间。
* 阶段二：副本控制器接受期望副本数，对比期望值与当前副本数实际值，如果实际值小于期望值，则进行扩容；如果实际值大于期望值，则进行缩容。
* 阶段三：调度模块检查到有新创建的Pod，根据调度策略将其调度到集群中合适的节点。
* 阶段四：kubelet具体执行Pod的创建过程，包括从Docker Registry下载镜像、应用容器的启动以及初始化等过程。
* 当Pod完成所有初始化工作后，kube-proxy修改转发列表，将新创建的Pod加入其中，这时新创建的Pod就可以对外提供服务。

因此，扩容时需要将Pod初始化时间考虑进去，在负载高峰到来之前做好扩容准备，减少用户的请求响应时间，从而保障服务质量的稳定性。

#### 缩容阶段问题分析

kubernetes自动缩容的目的在于当应用Pod副本集负载较低时，通过删除冗余副本提高副本集的整体资源利用率，降低应用的部署成本。

缩容阶段不仅要考虑删多少RC的副本的问题，还要考虑删哪个的问题。虽然Pod副本集中的副本都是由同一个模板创建出来的，但是各个副本在同一时刻会表现出很大的差异性。这是因为Kubernetes创建副本是一个动态的过程，有些正在被调度模块调度，有的已经被创建在节点上，而即使是在节点上的副本也会由很大的差别。

因此Kubernetes现有缩容策略在选择待删除副本时，首先根据副本集中各副本所处状态的不同赋予不同的优先级，根据优先级对副本进行排序，最终将优先级最小的副本作为待删副本。具体步骤如下：

1. 根据副本是否已经就绪分为未就绪副本和已就绪副本，未就绪副本优先级更小。
2. 对于未就绪副本分为未调度副本和已调度副本，未调度副本的优先级更小。
3. 对于已调度的副本根据其所处的状态分为Pending、Unknown、Running，Pending状态 < Unknow状态 < Running状态。
4. 对于已就绪副本，按照就绪时间长短确定优先级，时间较短的副本优先级小。
5. 优先级相等的副本根据内部容器重启次数确定优先级，重启次数较多的副本优先级更小。
6. 对于上面优先级相等的副本根据创建时间早晚确定优先级，时间晚的副本优先级较小。

删除优先级小的副本可以避免Kubernetes做一些无用的工作。

根据副本状态优先级来选择待删除副本，忽略删除Pod对集群资源的影响（敏感性？），可能会打破集群资源的平衡。

### 第4章 优化扩容策略的设计与实现

仅针对扩容阶段采取预测式策略，减少用户的响应时间；缩容阶段仍然采用响应式策略。

#### 4.1.1 负载预测模型

负载预测是通过总结已有的历史负载数据来对未来数据进行预测。历史数据是一段按照其发生时间排列成的数列。

指数平滑模型

短期时间序列的预测方法，计算量少、预测精度高，能够充分利用全部历史数据，并按照“重近轻远”的原则进行加权平均和修匀数据，较好地将时间序列所包含的历史规律挖掘出来。

一次指数平滑法适合预测具有水平发展趋势的时间序列，高次的指数平滑法时间复杂度较高，计算比较耗时。

灰色预测模型

灰色系统理论是以“部分样本信息已知，部分样本信息未知”的小样本来进行预测的算法模型，该模型主要通过对部分未知信息的生成来开发和提取有价值的信息，从而实现对系统运行规律的正确认识和确切描述。基于灰色系统理论GM(1,1)模型的预测方法称为灰色预测方法。灰色预测方法对于样本量小、变化规律不明显的样本有很好的适应性，同时灰色预测法的计算量小而且其定量分析结果和定性分析结果保持一致。

### 第5章 优化缩容策略的设计与实现

考虑删除副本后对集群负载均衡的影响，在缩容时预先计算删除副本后所在节点的资源利用率，并将其作为该副本的资源权值。