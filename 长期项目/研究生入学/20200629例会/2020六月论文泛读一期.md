# 2020六月论文泛读一期

标签：计算机论文 泛读 总结

[网络版本](https://github.com/wtysos11/NoteBook/issues/143)

## 其他

Performance Analysis of Cloud Applications，https://www.usenix.org/system/files/conference/nsdi18/nsdi18-ardelean.pdf。有点意思，好像和主题不搭，可以读一下。

Benchmark Requirements for Microservices Architecture Research，讲了如何对微服务进行测试。

## 概要

目的：调研学术界情况，下周展示

主要是：问题+解决问题的方法+思考，方法不用看太细，只看abstract和introduction，然后归类。进行的是文献的归类整理工作

重点是问题导向，即论文解决了什么问题。方法本身不用过多在意，效果倒是可以作为对比。

多服务相关的十点问题：
1. 资源相关
2. 响应时间相关
3. 整体扩缩。将贝叶斯/强化学习等作为黑盒使用，来对多个服务进行整体调度。最好是使用每个服务自身的指标，比如A->B，最好只用A的指标能检测出A超时。
4. 拓扑关系如何使用。
5. 超时检测。istio无法获得数据时如何定义。
6. 将预测式算法用于多服务中。发包：atOnceUser与constantUser
7. istio的熔断和流量控制如何用于多服务中
8. 注意力问题：如何关注哪些服务，共计多少资源。资源与动态变化的流量的配比。
9. 混合请求：对A和B的请求同时存在，如何准确找到需要扩缩的服务，增加资源的使用率。
10. 水平扩缩和垂直扩缩：维持CPU占用率在较高水平，提高资源使用率

关键问题：
1. 选择哪些服务进行扩缩
2. 使用哪些手段。

关键词：
* auto-scaling, cloud
* microservices
* multi-services
* cloud provisioning
* elasticity cloud
* topology
* latency
* vertical->horizontal

方法：
* google scholar
* WoS
* 顶会直接搜索
* 综述文献及参考文献

## 结果汇总

重要度按照五级评分，1为低，5为高。
|论文年份|论文名称|论文概述|属于哪一类|重要度|
|:-:|:-:| --- | --- | --- |
|2017 |Elasticity in Cloud Computing : State of the Art and Research Challenges |综述文献，主要是弹性调度领域相关的概念与使用的方法。被引161次 |综述类 |5|
|2018|Auto-Scaling Web Applications in Clouds : A Taxonomy and Survey Auto-scaling Web Applications in Clouds : A Taxonomy and Survey|综述文献，被引102次|综述类|5|
|2014|A Review of Auto-scaling Techniques for Elastic Applications in Cloud Environments|综述文献，被引441次|综述类|5|
|2019|Research on auto-scaling of web applications in cloud: survey, trends and future directions|综述文献，被引19次|综述类|5|
|2010|Cloud computing: State-of-the-art and research challenges|综述类文献，被引4130次|综述类|5|
|2010|QoS-aware infrastructure resources allocation in systems based on service-oriented architecture paradigm |关于SOA架构中资源分配的问题以及服务质量管理问题。使用排队论分析响应时间，拓扑结构是多层结构（线性）||2|
|2010|Autonomous Resource Provisioning for Multi-Service Web Applications|这是我看到的第一篇提到了multi-service的论文，是在SOA架构下进行的。同样使用排队论来分析响应时间，优点是服务调用采用了DAG||5|
|2014|Quality-of-service in cloud computing: modeling techniques and their applications|综述，被引220次。总结了QoS相关的建模方法|综述类|5|
|2019|Autonomic decentralized elasticity based on a reinforcement learning controller for cloud applications|使用强化学习，针对虚拟机环境，构造了一个分布式控制器来调度，分配资源，使得能够满足SLA的要求||3|
|2019|Predicting the End-to-End Tail Latency of Containerized Microservices in the Cloud|预测端到端时间延迟（95th percentile latency），来进行调度。使用机器学习方法，通过收集容器层、VM层和硬件层的指标来完成预测。特点是引入了服务之间的相互影响，因此没有使用排队论进行建模|2.响应时间|5|
|2020|Adaptive Microservices Scaling for Elastic Applications|使用机器学习和LSTM，构建预测式调度器。解决伸缩什么，以及何时如何伸缩的问题。||3|
|2016|A Resource Provisioning Strategy for Elastic Analytical Workflows in the Cloud|在响应时间的约束下以降低货币成本的方式配置资源，目的是最大化资源利用率。使用排队网络来建模，使用工作流作为拓扑关系||3|
|2016|Dynamic resource allocation using performance forecasting|使用预测式方法监控流量，直接估计所需要用的资源数量来进行调度||3|
|2016|Auto-scaling and deployment of web applications in distributed computing clouds|考虑了如何令服务在不同区域的数据中心部署时用户的响应时间最小这一问题，同时在分配资源尽量少时避免服务失败||2|
|2016|Building QoS-Aware Cloud Services|预测端到端时间延迟（95th percentile latency），来进行调度。使用机器学习方法，通过收集容器层、VM层和硬件层的指标来完成预测。特点是引入了服务之间的相互影响，因此没有使用排队论进行建模|2.响应时间|5|
|2017|Formal Approach for QoS-Aware Cloud Service Composition|问题是如何更好地进行Web Service Composition（SaaS层的问题），使得QoS最优化||1|
|2016|A fuzzy QoS-aware resource service selection considering design preference in cloud manufacturing system|Cloud manufacturing(CMfg问题)中不同QoS的值，资源同构，且用户需求动态时，如何解决CMfg中很少研究地测量模糊QoS，选择最佳服务进行调度的问题。方法是粒子群算法||1|
|2016|Resource Provisioning for Web Applications under Time-varying Traffic|使用排队论来建模，场景为a single-server model和two-stage tandem queue，探索这两种情况下变化流量与响应时间的关系||2|
|2018|Autonomic application topology redistribution|使用topology，使系统保持较高的资源占用率||3|


## 详细

### QoS-aware infrastructure resources allocation in systems based on service-oriented architecture paradigm

2010

关键词：QoS，SOA，resource allocation, response time guranties

从SOA方向搜到的一篇文章。文章考虑了在SOA范式中进行通信和计算资源分配任务的问题。资源的分配问题会分解成以某种方式为到来的服务请求分配资源。在分布式环境下的复杂应用的服务性能时间被用作服务质量衡量的指标。对系统的建模和服务响应时间的分析在本文中被用于构建一些资源分配的任务，比如best effort, IntServ和DiffServ。

本文所需要解决的任务：SOA架构下的资源分配和系统服务质量管理问题。

里面提到的复杂系统架构中，给出的图是多层线性结构。

### Autonomous Resource Provisioning for Multi-Service Web Applications

2010 Proceedings of the 19th International Conference on World Wide Web, WWW '10

关键词：Resource provisioning, multi-service application

问题：动态资源分配是为了在预先定义的SLA下维护网络应用的端到端时延。当SLA被违反时，必须要选择哪个服务应该被重新调度以获得最好的效果。本文最终证明系统可以在面对不同的负载的时候，同时增加服务器和缓存来满足SLA的要求并提高资源占用率。

#### 亮点

指出服务是具备基本功能的自包含应用（A service is a self-contained application providing elementary functionality）。

提到可以使用DAG来描述相互调用服务的拓扑关系。

提到对于multi-service web application来说，一个重要的问题是选择哪一个服务来进行调度，使得整个应用的维护接受表现达到最小的代价。

对整体服务的建模方法：
1. 将整体服务考虑为一个single queuing network
2. assign a fixed SLA to each service separately。这个问题是在本文中，没有任何内部服务SLA可以匹配整个系统的性能，按服务SLA方法必然浪费资源，因为当其等效时，某些服务很难维护其SLA。

关键：不用对系统中的所有服务都提供一个SLA，用户一般只关系端到端时延。

每个服务会自动评估自己在收到更多/更少资源，更多/更少负载时自己的表现。

最终的结果：系统可以在传统的多层应用与复杂的多服务应用(multi-service application)中取得较好的效果。

### Quality-of-service in cloud computing: modeling techniques and their applications

2014 Journal of Internet Services and Applications

算是一篇综述类文章，工作是providing a survey of the state of the art of QoS modeling approaches suitable for cloud systems。是对建模方法的总结。

3.1 Performance Models包括queueing systems,queueing networks和layered queueing networks，都是基于排队论方法进行的。

3.2 在Dependability models上的分析，包括Petri nets, Reliability Block Diagrams和Fault Trees。一般在云计算中使用第一个，或者说是改进版本的SPN(stochastic Petri nets)。

3.3 Black-box service models，服务模型被用于最优化网络服务组成。这里用于使用一个服务的响应时间来描述服务，假设缺少有关其内部的任何信息。（The idea behind the methods reviewed in this section is to describe a service in terms of its response time, assuming the lack of any further information concerning its internal characteristics (e.g., contention level from concurrent requests)）

3.4 Simulation models 描述的是云计算中所用到的虚拟环境.

从应用出发的关注问题：
1. Capacity allocation：如何在满足QoS的情况下分配资源。目标在于节省消耗。
2. Admission control：过载的时候如何保证QoS不退化。
3. load balancing：流量调度问题

### Autonomic decentralized elasticity based on a reinforcement learning controller for cloud applications

2019 Future Generation Computer Systems

来源：从Autonomous Resource Provisioning for Multi-Service Web Applications的被引用文章中搜索得到

将Web application分成了两类：transactional(e-commerce)and batch(text mining, video transcoding and graphical rendering)。Transactional workloads需要用户通过HTTP与应用进行交互。

这个类型的应用中，用户的体验与响应时间高度相关。Schurman和Brutlag证明，响应时间从200ms到500ms会导致收入降低1%。SLA的确立，确定了最差情况的目标。

Enterprise users establish service level agreements (SLAs) with web application owners that specify a target in terms of worst-case latency for a specific population of requests. For example, a target response time (e.g. 200 ms.) may be specified on the 95th percentile of a set of requests ordered by increasing response time. Missing this target requires the owner to pay a penalty to the user. The other important factor in the overall profit is the cost of infrastructure In the cloud model, this cost is the rental fee for using the resources that is levied on a per-time period (hourly, per-minute, etc.) by the provider.

会产生三个问题：1. 应用在服务器中的运行情况；2.当前数量的资源在面对到来流量时是否足够充足；3.资源是否被充分利用。

目标：开发一个控制器，可以让多个应用分布在不同的虚拟机上，取得较高的性能。

结果：开发了一个分布式架构来进行调度，以满足SLA。

使用方法：强化学习，针对虚拟机环境。

### Predicting the End-to-End Tail Latency of Containerized Microservices in the Cloud

2019 IEEE International Conference on Cloud Engineering (IC2E)

来源：从Autonomous Resource Provisioning for Multi-Service Web Applications的被引用文章中搜索得到

涉及到端对端时间延迟。（有相关论文，可以进一步扩展）涉及到拓扑关系。

问题：在缺乏准确地性能模型的情况下，管理流经微服务的情况的End-to-End latency是一个具有挑战性的工作。因为模型无法捕捉微服务工作流之间复杂的相互作用，并具有云诱发的性能可变性和服务间的性能依赖性(complex interplay of microservice workflows with cloudinduced performance variability and inter-service performance dependencies.)

本文的工作是，对于容器化的微服务提出了性能特征化的方法并进行了建模工作。

本文的建模方法允许云平台将不同层的资源使用指标，运用机器学习方法来预测端到端延迟。使用的数据包括云平台收集到的multi-layer data。（这里的multi-layer指的是虚拟化层，如container-layer,VM-layer and hardware performance coutner based metrics）

在kubernetes平台下进行实验，使用Sock Shop这个开源的微服务benchmark作为测试，结果是预测准确性很高。

#### 亮点

一般来说，会使用排队论来对多层应用进行建模（monolithic 3-tier application），这个方法在本文中不太适用，因为服务之间会相互影响。

Analytical modeling，作为一种白盒方法，需要对应用内部代码插入指令来进行workload profiling，并取得应用结构和数据流的专门数据。这个方法在云服务提供商角度是难以做到的，因为商业应用的可视化是受到严格限制的。

目前存在着黑盒建模方法，观测资源使用指标和资源分配指标。最近的研究也有使用runtime trace analysis tools and simulation based 方法来研究基于微服务的应用的性能。

但是没有人进行cloud induced performance interference on microservice-based applications的影响的研究。

### Adaptive Microservices Scaling for Elastic Applications

2020  IEEE Internet of Things Journal ( Volume: 7 , Issue: 5 , May 2020 )

背景：微服务诞生和IoT兴起，如何调度Web Application，用最小的资源达到目的。

工作：设计一个prototype auto-scaling system，为基于微服务的网络应用，可以从过去的服务经验中进行学习。
 The contributions of the work can be divided into two parts: 1) developing a pipeline for microservice auto-scaling and 2) evaluating a hybrid sequence and supervised learning model for recommending scaling actions.

问题：
1.  how to most effectively and efficiently auto-scale such an application
2.  key question with regards to auto-scaling such applications, given that nodes are heterogeneous in a microservices architecture, is “which microservice should be scaled?”（伸缩哪一个微服务）

贡献：使用预测式方法，解决伸缩什么，以及何时如何伸缩的问题。

方法：机器学习和LSTM进行预测

#### 亮点

其相关工作处总结了multi-tier的调度工作


### A Resource Provisioning Strategy for Elastic Analytical Workflows in the Cloud

2016 IEEE 18th International Conference on High Performance Computing and Communications; IEEE 14th International Conference on Smart City; IEEE 2nd International Conference on Data Science and Systems (HPCC/SmartCity/DSS)

问题：如何在响应时间的约束下以降低货币成本的方式配置资源。

使用analytical workflow来处理组件之间的关系。

方法：使用排队网络解决，进行建模。

应用管理者关系的两个因素：应用的性能和实际的金钱花费。挑战就是要决定合适的资源数量，能在最小化金钱消耗的同时最大化资源利用率。

### Dynamic resource allocation using performance forecasting

2016 International Conference on High Performance Computing & Simulation (HPCS)

如果使用响应式方法，一次调度一个实例，则速度缓慢，而且无法跟上快速变动的流量。在本文中，基于对资源变化的估计来进行分配。

可以根据当前处理的工作负载来估计所需要的流量数量。依据是Universal Scalability Law。

### Auto-scaling and deployment of web applications in distributed computing clouds

问题：如何选择地区使得响应时间最小、如何分配资源使得总消耗最小，同时保证服务质量避免失败。

贡献：
1. 使用了层次化的fuzzy inference approach
2. 使用了算法来选择数据中心来部署应用，从而最小化SLO的违约率。
3. 实现了一个自动弹性调度器
4. 一种方式，实现区域之间的负载平衡，减小短期应用超载造成的影响。

关键是geographical load balancing

###　Building QoS-Aware Cloud Services

2019 Joy Rahman的Phd论文。与Predicting the End-to-End Tail Latency of Containerized Microservices in the Cloud是同一作者。

问题：云计算中的服务经常面临超载(overhead)问题，从而导致服务质量下降

挑战：决定哪一个组件需要被伸缩，以及伸缩多少才能够满足SLO的目标。需要考虑动态地流量、组件间的性能与依赖关系，以及受到云影响的服务性能(cloud-induced performance interference)

对于第二个问题。
1.采用了基于机器学习的性能模型，将多层数据（容器层/虚拟机层/硬件层）结合来预测容器中的端到端时间延迟。
2. 使用概率机器学习算法，动态地调整系统参数，提供预测的置信区间。为在不确定云环境下进行资源管理决策提供参考。
3. 开发了一个有效的资源调度方法，在满足服务SLO的情况下最小化资源开销。

### Formal Approach for QoS-Aware Cloud Service Composition

2017 IEEE 26th International Conference on Enabling Technologies: Infrastructure for Collaborative Enterprises (WETICE)

提到了SaaS是基于SOA和网络服务技术

Web Service Composition是必要的，当单个服务无法满足需求时

目的：减少WSC的时间复杂度，对Web Service和它们的分解进行建模，使用Boolean satisfiability problem，可以将服务内部的结构视为行为兼容。这项工作的目的是 The aim of this work is the modelling and verification of Web Services Composition using a formal method based on Satisfiability (SAT)

当一个multiple web services compositions满足了用户的需求，最终WSC结果架构的QoS会最大化或最小化。

### A fuzzy QoS-aware resource service selection considering design preference in cloud manufacturing system

2016 The International Journal of Advanced Manufacturing Technology

Cloud manufacturing是一种先进的面向服务的manufacturing model。（制造业环境）

Resource service selection时应用Cmfg的一项重要技术，被用来面向灵活、松散耦合的服务应用的请求进行构建。面对大量拥有相似RSS功能的服务，QoS就可以反映用户的体验。

大量资源会被注入到资源池中，通过虚拟化的方式构建为面向用户的服务。

问题：面对大量异构QoSCmfg的价值、大量同构资源和动态的用户需求，如何解决CMfg中很少研究的测量模糊QoS并考虑设计偏好来选择最佳的服务的问题。

总结：资源服务选择的问题，其中QoS是fuzzy and uncertain的。与云计算相关。

### Resource Provisioning for Web Applications under Time-varying Traffic

2016 一本书207页，使用排队论来进行建模

场景为两个：a single-server model和two-stage tandem queue，对这两种情况下面对随时间变化流量时响应时间的关系进行了建模

主要使用的模型是Markov-modulated Poisson process

### Autonomic application topology redistribution

2018 硕士论文 university of groningen（荷兰）

关注的是资源占用率的问题。系统使用的MAPE-K by IBM。会对流量进行预测，并选择一个更好的路线(From that prediction, it makes an adaptation plan if necessary by selecting a more
suitable topology to handle the predicted load and finally redeploys
the application with the more adequate topology)

微服务架构，使用了容器

比较令人迷惑的是其topology的定义：A switch occurs if the application topology
doesn’t meet the service level objectives specified by the owner of the
application and it is either under using or over using the resources
provided to it hence costing the application owner either financially
or in terms having their application have poor performance.当SLA不能被满足的时候，会切换topology

而且前面也有提到，topology似乎是用户提供的

### Open Issues in Scheduling Microservices in the Cloud

2016 IEEE Cloud Computing

文章主要描述了采用微服务的优点与挑战。算是入门、介绍类文章

Topology and Orchestration Specification for Cloud Applications 用于描述云的Web应用的拓扑结构

一些介绍

### ACCELERATING PERFORMANCE IN CRITICAL TOPOLOGY ANALYSIS OF DISTRIBUTION MANAGEMENT SYSTEM PROCESS BY SWITCHING FROM MONOLITHIC TO MICROSERVICES 

提到的SOA和微服务的区别。它的说法是，SOA是单应用的，其多个服务可以是同一个。微服务架构下多个服务都是不同的。

本文中在一个分布式管理系统（电力）中使用微服务架构，要求能够增加系统可用性，阻止过载。

工具：拓扑分析，使用Microsoft Azure Service Fabric

### PERFORMANCE EVALUATION OF MASSIVELY DISTRIBUTED MICROSERVICES BASED APPLICATIONS

In this paper we provide a simulation based approach to explore the impact of microservicebased software architectures in terms of performances and
dependability, given a desired configuration.

开发了一个基于模拟的方法，来探索微服务架构下性能和依赖的影响，给出一个期望的配置。

目的是期望能够对于不同种类的微服务应用，在不同的系统配置下，给出其行为在随机流量下产生作用的估计，（infrastructure角度）

### Speeding up distributed request-response workflows

问题：Bing下的服务器响应时间过长，原因是内部的访问包含许多线性结构（sequential stages）和并行结构。

It decomposes the problem of minimizing latency over a general processing DAG into a manageable optimization over individual stages.

### Burst-Aware Predictive Autoscaling for Containerized Microservices

### Adaptive Microservice Scaling for Elastic Applications

### Towards an Adaptive, Fully Automated Performance Modeling Methodology for Cloud Applications

### Adaptive Resource Allocation and Provisioning in Multi-Service Cloud Environments